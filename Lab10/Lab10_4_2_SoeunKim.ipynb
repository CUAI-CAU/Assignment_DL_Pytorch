{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab10_4_2_SoeunKim.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03POSkwwJxwj",
        "outputId": "c97f2a11-9244-4e9b-e6b8-683698912c0b"
      },
      "source": [
        "!git clone https://github.com/deeplearningzerotoall/PyTorch/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PyTorch'...\n",
            "remote: Enumerating objects: 1899, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 1899 (delta 91), reused 88 (delta 88), pack-reused 1803\u001b[K\n",
            "Receiving objects: 100% (1899/1899), 80.33 MiB | 36.02 MiB/s, done.\n",
            "Resolving deltas: 100% (242/242), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pxs-fpBKAUA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz1tSkRjKfQg"
      },
      "source": [
        "torch.manual_seed(777)\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFajP8AJKhxJ",
        "outputId": "e8db7915-7ded-47c6-dacc-f5c91eff23cd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO3iYiXMK6Te"
      },
      "source": [
        "trans = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_data = torchvision.datasets.ImageFolder(root='/content/PyTorch/custom_data/train_data', transform=trans)\n",
        "data_loader = DataLoader(dataset = train_data, batch_size = 8, shuffle = True, num_workers=2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PiJ6dabLo8p"
      },
      "source": [
        "# model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3,6,5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(6,16,5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(16*13*29, 120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120,2)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        out = self.layer3(out)\n",
        "        return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "230XedsrLuLz"
      },
      "source": [
        "# testing \n",
        "net = CNN().to(device)\n",
        "test_input = (torch.Tensor(3,3,64,128)).to(device)\n",
        "test_out = net(test_input)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIDbjcO5LwpP"
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=0.00005)\n",
        "loss_func = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZC7W6zALys2",
        "outputId": "f3c87301-5746-4730-cd80-26caba124810"
      },
      "source": [
        "total_batch = len(data_loader)\n",
        "\n",
        "epochs = 7\n",
        "for epoch in range(epochs):\n",
        "    avg_cost = 0.0\n",
        "    for num, data in enumerate(data_loader):\n",
        "        imgs, labels = data\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = net(imgs)\n",
        "        loss = loss_func(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        avg_cost += loss / total_batch\n",
        "        \n",
        "    print('[Epoch:{}] cost = {}'.format(epoch+1, avg_cost))\n",
        "print('Learning Finished!')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:1] cost = 0.6551658511161804\n",
            "[Epoch:2] cost = 0.4942258596420288\n",
            "[Epoch:3] cost = 0.23500534892082214\n",
            "[Epoch:4] cost = 0.06870826333761215\n",
            "[Epoch:5] cost = 0.026445452123880386\n",
            "[Epoch:6] cost = 0.013893328607082367\n",
            "[Epoch:7] cost = 0.008642658591270447\n",
            "Learning Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkRT0VPzQ56Z"
      },
      "source": [
        "torch.save(net.state_dict(), '/content/PyTorch/model/model.pth')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp-EM1UEL522"
      },
      "source": [
        "new_net = CNN().to(device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNT7nNs32GbO",
        "outputId": "4834cfd5-a075-46d8-839d-0dabcdff0a8f"
      },
      "source": [
        "new_net.load_state_dict(torch.load('/content/PyTorch/model/model.pth'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tXWswQ5MBGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26169bb5-e716-4115-c160-3bcbbde37319"
      },
      "source": [
        "print(net.layer1[0])\n",
        "print(new_net.layer1[0])\n",
        "\n",
        "print(net.layer1[0].weight[0][0][0])\n",
        "print(new_net.layer1[0].weight[0][0][0])\n",
        "\n",
        "net.layer1[0].weight[0] == new_net.layer1[0].weight[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "tensor([-0.0915,  0.0031, -0.0173, -0.0214,  0.0929],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([-0.0915,  0.0031, -0.0173, -0.0214,  0.0929],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[True, True, True, True, True],\n",
              "         [True, True, True, True, True],\n",
              "         [True, True, True, True, True],\n",
              "         [True, True, True, True, True],\n",
              "         [True, True, True, True, True]],\n",
              "\n",
              "        [[True, True, True, True, True],\n",
              "         [True, True, True, True, True],\n",
              "         [True, True, True, True, True],\n",
              "         [True, True, True, True, True],\n",
              "         [True, True, True, True, True]],\n",
              "\n",
              "        [[True, True, True, True, True],\n",
              "         [True, True, True, True, True],\n",
              "         [True, True, True, True, True],\n",
              "         [True, True, True, True, True],\n",
              "         [True, True, True, True, True]]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfY7JYXbMzja"
      },
      "source": [
        "test_image = '/content/PyTorch/custom_data/test_data'\n",
        "\n",
        "trans=torchvision.transforms.Compose([\n",
        "    transforms.Resize((64,128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "test_data = torchvision.datasets.ImageFolder(root=test_image, transform=trans)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3BULbkoM3ad"
      },
      "source": [
        "test_set = DataLoader(dataset = test_data, batch_size = len(test_data))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QuJGaXT2ROM",
        "outputId": "7b0f0e20-5cc2-4963-d0e9-6ea0de2f7614"
      },
      "source": [
        "# test\n",
        "with torch.no_grad():\n",
        "    for num, data in enumerate(test_set):\n",
        "        imgs, label = data\n",
        "        imgs = imgs.to(device)\n",
        "        label = label.to(device)\n",
        "        \n",
        "        prediction = net(imgs)\n",
        "        \n",
        "        correct_prediction = torch.argmax(prediction, 1) == label\n",
        "        \n",
        "        accuracy = correct_prediction.float().mean()\n",
        "        print('Accuracy:', accuracy.item())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}