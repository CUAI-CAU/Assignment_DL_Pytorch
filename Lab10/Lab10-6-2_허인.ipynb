{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Lab10-6-2_허인.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"HOF_4dVX7nFh"},"source":["# ResNet for cifar10"]},{"cell_type":"code","metadata":{"id":"xD6zd3JE7nFl"},"source":["import torch\n","import torch.nn as nn\n","\n","import torch.optim as optim\n","\n","import torchvision\n","import torchvision.transforms as transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"c8US66NW7nFn"},"source":["import visdom\n","\n","vis = visdom.Visdom()\n","vis.close(env=\"main\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"utIJ4d_Y7nFo"},"source":["def value_tracker(value_plot, value, num):\n","    '''num, loss_value, are Tensor'''\n","    vis.line(X=num,\n","             Y=value,\n","             win = value_plot,\n","             update='append'\n","             )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T07uWxtG7nFo"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","torch.manual_seed(777)\n","if device =='cuda':\n","    torch.cuda.manual_seed_all(777)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VVWVxMYd7nFp"},"source":["## How to Calculate mean and std in Normalize "]},{"cell_type":"code","metadata":{"scrolled":true,"id":"AtbtLqMt7nFp"},"source":["transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n","\n","print(trainset.train_data.shape)\n","\n","train_data_mean = trainset.train_data.mean( axis=(0,1,2) )\n","train_data_std = trainset.train_data.std( axis=(0,1,2) )\n","\n","\n","print(train_data_mean)\n","print(train_data_std)\n","\n","train_data_mean = train_data_mean / 255\n","train_data_std = train_data_std / 255\n","\n","print(train_data_mean)\n","print(train_data_std)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9-kYFEL67nFq"},"source":["transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4), transforms.ToTensor(), transforms.Normalize(train_data_mean, train_data_std)])\n","transform_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize(train_data_mean, train_data_std)])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=0)\n","\n","testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=0)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gDpascJH7nFq"},"source":["## make ResNet50 using resnet.py"]},{"cell_type":"code","metadata":{"id":"RmlR2kIS7nFq"},"source":["import resnet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lnw2Ojb77nFr"},"source":["conv1x1=resnet.conv1x1\n","Bottleneck = resnet.Bottleneck\n","BasicBlock= resnet.BasicBlock"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Jnwm4C17nFr"},"source":["class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n","        super(ResNet, self).__init__()\n","        self.inplanes = 16\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.relu = nn.ReLU(inplace=True)\n","        \n","        self.layer1 = self._make_layer(block, 16, layers[0], stride=1)\n","        self.layer2 = self._make_layer(block, 32, layers[1], stride=1)\n","        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 128, layers[3], stride=2)\n","        \n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(128 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # residual branch starts with zeros, each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% \n","\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layer1(x) #x.shape =[1, 128, 32,32]\n","        x = self.layer2(x) #x.shape =[1, 256, 32,32]\n","        x = self.layer3(x) #x.shape =[1, 512, 16,16]\n","        x = self.layer4(x) #x.shape =[1, 1024, 8,8]\n","        \n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TNUIftTj7nFs"},"source":["resnet50 = ResNet(resnet.Bottleneck, [3, 4, 6, 3], 10, True).to(device) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZ2RXYky7nFs"},"source":["resnet50"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Ij61e3Gk7nFt"},"source":["a=torch.Tensor(1,3,32,32).to(device)\n","out = resnet50(a)\n","print(out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJzq6P4L7nFt"},"source":["criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = torch.optim.SGD(resnet50.parameters(), lr = 0.1, momentum = 0.9, weight_decay=5e-4)\n","lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q4o5BeIk7nFu"},"source":["loss_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))\n","acc_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='Accuracy', legend=['Acc'], showlegend=True))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jnXgUFaf7nFv"},"source":["def acc_check(net, test_set, epoch, save=1):\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in test_set:\n","            images, labels = data\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = net(images)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    \n","    acc = (100 * correct / total)\n","    print('Accuracy of network on 10000 test images: %d' % acc)\n","    if save:\n","        torch.save(net.state_dict(), \"./model/model_epoch_{}_acc_{}.pth\".format(epoch, int(acc)))\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QtlvFVVE7nFv"},"source":["## Training with (acc check + model save)"]},{"cell_type":"code","metadata":{"id":"HU0nCSTU7nFv"},"source":["print(len(trainloader))\n","epochs = 150\n","\n","for epoch in range(epochs):  # loop over dataset multiple times\n","\n","    running_loss = 0.0\n","    lr_sche.step()\n","    for i, data in enumerate(trainloader, 0):\n","\n","        # get the inputs\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = resnet50(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 30 == 29:    # print every 30 mini-batches\n","            value_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch*len(trainloader) ]))\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 30))\n","            running_loss = 0.0\n","    \n","    #Check Accuracy\n","    acc = acc_check(resnet50, testloader, epoch, save=1)\n","    value_tracker(acc_plt, torch.Tensor([acc]), torch.Tensor([epoch]))\n","    \n","\n","print('Finished')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uZftCskS7nFw"},"source":["## Model Accuracy Test"]},{"cell_type":"code","metadata":{"id":"2W6RnPuT7nFw"},"source":["correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = resnet50(images)\n","        \n","        _, predicted = torch.max(outputs.data, 1)\n","        \n","        total += labels.size(0)\n","        \n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of network on 10000 test images: %d' % (correct / total))"],"execution_count":null,"outputs":[]}]}