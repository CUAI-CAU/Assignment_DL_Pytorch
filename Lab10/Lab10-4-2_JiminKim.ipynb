{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqPoL4P-mP1s"
   },
   "source": [
    "## Image Folder를 활용하여 커스텀 데이터 셋 생성 후 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 데이터 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴더 PATH의 목록입니다.\n",
      "볼륨 일련 번호는 5375-3C31입니다.\n",
      "C:.\n",
      "├─.ipynb_checkpoints\n",
      "├─MNIST_data\n",
      "│  └─MNIST\n",
      "│      └─raw\n",
      "└─MyData\n",
      "    ├─test_data\n",
      "    │  ├─0\n",
      "    │  └─1\n",
      "    └─train_data\n",
      "        ├─0\n",
      "        └─1\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터가 들어있는 폴더 살펴보기\n",
    "!tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크기 조정\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor()\n",
    "                      ])\n",
    "\n",
    "# 학습용 데이터 생성(59개)\n",
    "train_data = torchvision.datasets.ImageFolder(root='./MyData/train_data', transform=trans)\n",
    "data_loader = DataLoader(dataset = train_data, batch_size = 4, shuffle = True, num_workers=2)\n",
    "\n",
    "# 평가용 데이터 생성(10개)\n",
    "test_data = torchvision.datasets.ImageFolder(root='./MyData/test_data', transform=trans)\n",
    "test_set = DataLoader(dataset = test_data, batch_size = len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 전체 데이터 셋 :  59\n",
      "학습 배치 묶음 개수 :  15\n",
      "\n",
      "평가 전체 데이터 셋 :  10\n",
      "평가 배치 묶음 개수 :  1\n"
     ]
    }
   ],
   "source": [
    "# 생성된 데이터 확인\n",
    "print(\"학습 전체 데이터 셋 : \",len(data_loader.dataset))\n",
    "print(\"학습 배치 묶음 개수 : \", len(data_loader))\n",
    "\n",
    "print(\"\\n평가 전체 데이터 셋 : \",len(test_set.dataset))\n",
    "print(\"평가 배치 묶음 개수 : \", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32])\n",
      "tensor([0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "for img,label in data_loader:\n",
    "    print(img.size())\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3,6,4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6,2,4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(2*5*5, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        #print(\"after layer1 : \",out.shape)\n",
    "        out = self.layer2(out)\n",
    "        #print(\"after layer2 : \",out.shape)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        #print(\"after view : \",out.shape)\n",
    "        out = self.layer3(out)\n",
    "        #print(\"after layer3 : \",out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 29, 29]             294\n",
      "              ReLU-2            [-1, 6, 29, 29]               0\n",
      "         MaxPool2d-3            [-1, 6, 14, 14]               0\n",
      "            Conv2d-4            [-1, 2, 11, 11]             194\n",
      "              ReLU-5            [-1, 2, 11, 11]               0\n",
      "         MaxPool2d-6              [-1, 2, 5, 5]               0\n",
      "            Linear-7                   [-1, 32]           1,632\n",
      "              ReLU-8                   [-1, 32]               0\n",
      "            Linear-9                    [-1, 2]              66\n",
      "================================================================\n",
      "Total params: 2,186\n",
      "Trainable params: 2,186\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.09\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트\n",
    "from torchsummary import summary\n",
    "net = CNN().to(device)\n",
    "summary(net,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(6, 2, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch 1) cost = 0.69047\n",
      "(epoch 2) cost = 0.68657\n",
      "(epoch 3) cost = 0.68131\n",
      "(epoch 4) cost = 0.67542\n",
      "(epoch 5) cost = 0.65748\n",
      "(epoch 6) cost = 0.63865\n",
      "(epoch 7) cost = 0.60129\n",
      "(epoch 8) cost = 0.54549\n",
      "(epoch 9) cost = 0.47623\n",
      "(epoch 10) cost = 0.38359\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0.0\n",
    "    for num, data in enumerate(data_loader):\n",
    "        imgs, labels = data\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = net(imgs)\n",
    "      \n",
    "        loss = loss_func(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += loss / total_batch\n",
    "        \n",
    "    print('(epoch %d) cost = %.5f'%(epoch+1, avg_cost))\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"./model/customModel.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 저장된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_net = CNN().to(device)\n",
    "new_net.load_state_dict(torch.load('./model/customModel.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for num, data in enumerate(test_set):\n",
    "        imgs, label = data\n",
    "        imgs = imgs.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        prediction = new_net(imgs)\n",
    "        \n",
    "        correct_prediction = torch.argmax(prediction, 1) == label\n",
    "        \n",
    "        accuracy = correct_prediction.float().mean()\n",
    "        print('Accuracy:', accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNLfR2BldaV6l4/5cgQZ1I+",
   "collapsed_sections": [],
   "name": "Lab10-4-2_JiminKim.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
