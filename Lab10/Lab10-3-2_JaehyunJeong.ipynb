{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab-10_3_2_MNIST-CNN with Visdom\n",
    "##### JaehyunJeong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 26910,
     "status": "ok",
     "timestamp": 1636431084997,
     "user": {
      "displayName": "Jimin Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXY4Z58QWqdf0_emFTik194qt20j1LbvN1ymGJsBI=s64",
      "userId": "03179597400061085718"
     },
     "user_tz": -540
    },
    "id": "3M_K1HUT41qQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.init\n",
    "\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18053,
     "status": "ok",
     "timestamp": 1636431533439,
     "user": {
      "displayName": "Jimin Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXY4Z58QWqdf0_emFTik194qt20j1LbvN1ymGJsBI=s64",
      "userId": "03179597400061085718"
     },
     "user_tz": -540
    },
    "id": "uDFxfxi15DhK",
    "outputId": "c9d014fa-7a62-4d0e-e537-c8a001d0df01"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sskn8xLJ6yl0"
   },
   "source": [
    "## define loss_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_tracker(loss_plot, loss_value, num):\n",
    "    vis.line(X=num,\n",
    "            Y=loss_value,\n",
    "            win=loss_plot,\n",
    "            update='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디바이스 및 시드값 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "    \n",
    "    \n",
    "# 파라미터 설정\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 준비\n",
    "mnist_train = dsets.MNIST(root='./MNIST_data/',\n",
    "                         train = True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='./MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform = transforms.ToTensor(),\n",
    "                        download=True)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = True,\n",
    "                                         drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.keep_prob = 0.5\n",
    "\n",
    "        # conv layer\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=3, stride=1, padding=1), # 입력 채널 1, 출력 채널(필터 갯수) 32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # conv layer\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # conv layer\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64,128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*128, 625, bias=True) # 4*4 사이즈의 맵이 64개(입력), 625(출력)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight) # fc층은 가중치 초기화 적용\n",
    "\n",
    "        # fc layer\n",
    "        self.layer4 = nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p = self.keep_prob)\n",
    "        )\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias = True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x) # conv\n",
    "        out = self.layer2(out) # conv\n",
    "        out = self.layer3(out) # conv\n",
    "        out = out.view(out.size(0), -1) # flatten\n",
    "        out = self.layer4(out) # fc\n",
    "        out = self.fc2(out) # fc\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "# 파라미터 정의\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사분면 그리기\n",
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training with loss_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch :  1] cost = 0.155277029\n",
      "[Epoch :  2] cost = 0.0511719361\n",
      "[Epoch :  3] cost = 0.0370592289\n",
      "[Epoch :  4] cost = 0.0295228884\n",
      "[Epoch :  5] cost = 0.0231849477\n",
      "[Epoch :  6] cost = 0.0188196134\n",
      "[Epoch :  7] cost = 0.0175009556\n",
      "[Epoch :  8] cost = 0.0149418386\n",
      "[Epoch :  9] cost = 0.0150751816\n",
      "[Epoch : 10] cost = 0.0110050235\n",
      "[Epoch : 11] cost = 0.0124356896\n",
      "[Epoch : 12] cost = 0.00971969031\n",
      "[Epoch : 13] cost = 0.0113638993\n",
      "[Epoch : 14] cost = 0.0101935379\n",
      "[Epoch : 15] cost = 0.00978853367\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "total_batch = len(data_loader) # 600개의 배치 묶음\n",
    "model.train() # dropout = True\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader : # (image, label)\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "\n",
    "        cost = criterion(hypothesis, Y) # 한 배치묶음(100개의 이미지)의 평균 loss(cost)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch : {:>2}] cost = {:.9}'.format(epoch+1, avg_cost))\n",
    "    loss_tracker(loss_plt, torch.Tensor([avg_cost]), torch.Tensor([epoch])) # loss tracker\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.95020\n"
     ]
    }
   ],
   "source": [
    "# test model and check accuracy\n",
    "with torch.no_grad():\n",
    "    model.eval() # dropout = False\n",
    "\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28,28).float().to(device) # 배치사이즈*\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('accuracy : {:.5f}'.format(accuracy.item()))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMkm+l8Vv1W1S7N7JPSLhUw",
   "collapsed_sections": [],
   "name": "Lab10-3-2_JiminKim.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
