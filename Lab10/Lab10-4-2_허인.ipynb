{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab10-4-2_허인.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPSs1iv7KRAmrySWBtkdOT8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"NDNwEZytsqsW"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","import torchvision\n","import torchvision.transforms as transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FYdOSgKDuX9z"},"source":["# GPU\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","torch.manual_seed(777)\n","if device =='cuda':\n","    torch.cuda.manual_seed_all(777)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"toaDZiKJP8sK"},"source":["#Data Load\n","trans = transforms.Compose([transforms.ToTensor()]) #ToTensor\n","train_data = torchvision.datasets.ImageFolder(root='./custom_data/train_data', transform=trans)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IdFUhQqVucc5"},"source":["data_loader = DataLoader(dataset = train_data, batch_size = 8, \n","                         shuffle = True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4xATu2TuebP"},"source":["#CNN Model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3,6,5),  #RGB 3 channel input, 6 channel output, filter 5\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),)\n","\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(6,16,5),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),)\n","\n","        #FC Layer\n","        self.layer3 = nn.Sequential(\n","            nn.Linear(16*13*29, 120), #FC1\n","            nn.ReLU(),\n","            nn.Linear(120,2)). #FC2\n","        \n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.view(out.shape[0], -1) #Flatten\n","        out = self.layer3(out)\n","        return out    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fEdjHsnhugHa"},"source":["#testing \n","net = CNN().to(device)\n","test_input = (torch.Tensor(3,3,64,128)).to(device)\n","test_out = net(test_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPf7Cf3EuhmR"},"source":["optimizer = optim.Adam(net.parameters(), lr=0.00005)\n","loss_func = nn.CrossEntropyLoss().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9QmHbeN4uirh"},"source":["total_batch = len(data_loader)\n","epochs = 7\n","\n","#Model 학습\n","for epoch in range(7):\n","    avg_cost = 0.0\n","    for num, data in enumerate(data_loader):\n","        imgs, labels = data\n","\n","        imgs = imgs.to(device) #독립변수\n","        labels = labels.to(device) #종속변수\n","\n","        optimizer.zero_grad()\n","        out = net(imgs) #모델에 독립변수를 넣어 Prediction\n","        loss = loss_func(out, labels)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        avg_cost += loss / total_batch\n","        \n","    print('[Epoch: %4d] cost = %.9f' %(epoch + 1, avg_cost))\n","print('Learning Finished')   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7QEyUxoPukQw"},"source":["#Trained CNN Model -> save\n","torch.save(net.state_dict(), \"./model/model.pth\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKrkazt9umAu"},"source":["new_net = CNN().to(device)\n","new_net.load_state_dict(torch.load('./model/model.pth'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nw53aQ9JuoDB"},"source":["#Pretrained CNN Model\n","print(net.layer1[0])\n","print(new_net.layer1[0])\n","\n","print(net.layer1[0].weight[0][0][0])\n","print(new_net.layer1[0].weight[0][0][0])\n","\n","net.layer1[0].weight[0] == new_net.layer1[0].weight[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gdn3sNj9upIN"},"source":["#Pretrained CNN Model: Test Data Load\n","trans=torchvision.transforms.Compose([transforms.Resize((64,128)),\n","                                      transforms.ToTensor()])\n","test_data = torchvision.datasets.ImageFolder(root='./custom_data/test_data', transform=trans)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vGSwKqdurq_"},"source":["test_set = DataLoader(dataset = test_data, \n","                      batch_size = len(test_data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p2dbjJicus4V"},"source":["#Pretrained CNN Model: Model Evaluation\n","with torch.no_grad():\n","    for num, data in enumerate(test_set):\n","        imgs, label = data\n","        imgs = imgs.to(device)\n","        label = label.to(device)\n","        \n","        prediction = net(imgs)\n","        \n","        correct_prediction = torch.argmax(prediction, 1) == label\n","        \n","        accuracy = correct_prediction.float().mean()\n","        print('Accuracy:', accuracy.item())"],"execution_count":null,"outputs":[]}]}