{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73,80,75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96,98,100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[196],[142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-847c1e48d4a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhypothesis\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#optimizer 설정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#optimizer 사용법\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optim' is not defined"
     ]
    }
   ],
   "source": [
    "# H(x) 계산\n",
    "hypothesis = x_train.matmul(W) + b\n",
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "#optimizer 설정\n",
    "optimizer = optim.SGD([W,b],lr = 1e-5)\n",
    "\n",
    "#optimizer 사용법\n",
    "optimizer.zero_grad()\n",
    "cost.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros((3,1),requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([W,b],lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 20 hypothesis tensor([0., 0., 0., 0., 0.]) Cost: 29661.80078125\n",
      "Epoch 1 20 hypothesis tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]) Cost: 9298.5205078125\n",
      "Epoch 2 20 hypothesis tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]) Cost: 2915.712890625\n",
      "Epoch 3 20 hypothesis tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]) Cost: 915.04052734375\n",
      "Epoch 4 20 hypothesis tensor([137.7968, 165.6247, 163.1911, 177.7112, 126.3307]) Cost: 287.9360046386719\n",
      "Epoch 5 20 hypothesis tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]) Cost: 91.37100982666016\n",
      "Epoch 6 20 hypothesis tensor([148.1035, 178.0144, 175.3980, 191.0042, 135.7812]) Cost: 29.75813865661621\n",
      "Epoch 7 20 hypothesis tensor([150.1744, 180.5042, 177.8508, 193.6753, 137.6805]) Cost: 10.445304870605469\n",
      "Epoch 8 20 hypothesis tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]) Cost: 4.391228199005127\n",
      "Epoch 9 20 hypothesis tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]) Cost: 2.493135452270508\n",
      "Epoch 10 20 hypothesis tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]) Cost: 1.8976879119873047\n",
      "Epoch 11 20 hypothesis tensor([152.5485, 183.3610, 180.6640, 196.7389, 139.8602]) Cost: 1.7105414867401123\n",
      "Epoch 12 20 hypothesis tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]) Cost: 1.6514123678207397\n",
      "Epoch 13 20 hypothesis tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]) Cost: 1.6323868036270142\n",
      "Epoch 14 20 hypothesis tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]) Cost: 1.6259231567382812\n",
      "Epoch 15 20 hypothesis tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]) Cost: 1.6234121322631836\n",
      "Epoch 16 20 hypothesis tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]) Cost: 1.6221405267715454\n",
      "Epoch 17 20 hypothesis tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]) Cost: 1.6212533712387085\n",
      "Epoch 18 20 hypothesis tensor([152.7999, 183.6688, 180.9644, 197.0662, 140.0963]) Cost: 1.620499610900879\n",
      "Epoch 19 20 hypothesis tensor([152.8014, 183.6715, 180.9666, 197.0686, 140.0985]) Cost: 1.6197700500488281\n",
      "Epoch 20 20 hypothesis tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.1000]) Cost: 1.619032621383667\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "    \n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch',epoch,nb_epochs, 'hypothesis',hypothesis.squeeze().detach(),'Cost:',cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    " # nn.Module 이 존재해서 우리의 편의를 증가 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def _int_(self):\n",
    "        sef.x_data = [[73,80,75],\n",
    "                            [93, 88, 93],\n",
    "                            [89, 91, 90],\n",
    "                            [96,98,100],\n",
    "                            [73, 66, 70]]\n",
    "        self.y_data = [[152],[185],[180],[196],[142]]\n",
    "        \n",
    "        def _len_(self):\n",
    "            return len(self.x_data)\n",
    "        \n",
    "        def _getitem_(self,idx) :\n",
    "            x = torch.FloatTensor(self.x_data[idx])\n",
    "            y = torch.FloatTensor(self.y_data[idx])\n",
    "            \n",
    "            return x, y\n",
    "dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'CustomDataset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-4e3bcafce3b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m dataloader = DataLoader(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[0;32m    268\u001b[0m                     \u001b[1;31m# Cannot statically verify that dataset is Sized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m                     \u001b[1;31m# Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m     99\u001b[0m                              \"since a random permute will be performed.\")\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m    103\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001b[0m in \u001b[0;36mnum_samples\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# dataset size might change at runtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'CustomDataset' has no len()"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    ")\n",
    "# 이 부분을 이해하기 어려웠다. 설명도 짧고 코드에 대한 해석도 부족했다.\n",
    "# 과제를 하다보니 느낀건데 내가 너무 주석을 안 쓴 듯 하다...하....다음엔 열심히 써야지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
