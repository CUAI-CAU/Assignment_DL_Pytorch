{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Lab11-6_허인.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"NdLrRsR-2o_s"},"source":["# PackedSequence & PaddedSequence"]},{"cell_type":"code","metadata":{"id":"h4uTlViK1tXr"},"source":["import torch\n","import numpy as np\n","from torch.nn.utils.rnn import pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hp12QrkS1tXs"},"source":["## 예제 데이터\n","\n","batch size가 5이고, sequence 중 가장 긴 길이는 13"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"aeuRLKty1tXs","outputId":"529ee7e5-c5f2-49dc-c439-955bff290e20"},"source":["# Random word from random word generator\n","data = ['hello world',\n","        'midnight',\n","        'calculation',\n","        'path',\n","        'short circuit']\n","\n","# Make dictionary\n","char_set = ['<pad>'] + list(set(char for seq in data for char in seq)) # Get all characters and include pad token\n","char2idx = {char: idx for idx, char in enumerate(char_set)} # Constuct character to index dictionary\n","print('char_set:', char_set)\n","print('char_set length:', len(char_set))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["char_set: ['<pad>', 'm', 'i', 'd', 'l', 'n', 'r', 't', 's', 'a', 'e', ' ', 'p', 'u', 'c', 'h', 'w', 'o', 'g']\n","char_set length: 19\n"]}]},{"cell_type":"code","metadata":{"id":"WOHDqrH81tXt","outputId":"2b6045ff-2503-4397-d63c-91da04f782b3"},"source":["# Convert character to index and make list of tensors\n","X = [torch.LongTensor([char2idx[char] for char in seq]) for seq in data]\n","\n","# Check converted result\n","for sequence in X: print(sequence)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([15, 10,  4,  4, 17, 11, 16, 17,  6,  4,  3])\n","tensor([ 1,  2,  3,  5,  2, 18, 15,  7])\n","tensor([14,  9,  4, 14, 13,  4,  9,  7,  2, 17,  5])\n","tensor([12,  9,  7, 15])\n","tensor([ 8, 15, 17,  6,  7, 11, 14,  2,  6, 14, 13,  2,  7])\n"]}]},{"cell_type":"markdown","metadata":{"id":"jt4w7p521tXt"},"source":["sequence의 길이가 제각각\n","\n"]},{"cell_type":"code","metadata":{"id":"8jXHmWzW1tXu","outputId":"bcd35cf1-c6d5-4e33-c56e-b940be80a41c"},"source":["# Make length tensor (will be used later in 'pack_padded_sequence' function)\n","lengths = [len(seq) for seq in X]\n","print('lengths:', lengths)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["lengths: [11, 8, 11, 4, 13]\n"]}]},{"cell_type":"markdown","metadata":{"id":"iX18DNXi1tXu"},"source":["# Sequence 데이터의 경우 어떻게 batch로 묶을까\n","Text나 audio처럼 sequence 형식인 데이터의 경우 길이가 각각 다르기 때문에 하나의 batch로 만들어주기 위해서 일반적으로 제일 긴 sequence 길이에 맞춰 뒷부분에 padding을 추가.\n","** 일반적으로 많이 쓰이는 Padding 방식\n","but! PyTorch에서는 'PackedSequence'을 쓰면 padding 없이도 정확히 필요한 부분까지만 병렬 계산 가능"]},{"cell_type":"markdown","metadata":{"id":"QpQESjjD1tXu"},"source":["# `pad_sequence` 함수 -> PaddedSequence (그냥 Tensor) 만들기"]},{"cell_type":"code","metadata":{"id":"meZy54jU1tXv","outputId":"7c47b0a2-435b-4c07-c1cc-c6cef4fe4fe8"},"source":["# Make a Tensor of shape (Batch x Maximum_Sequence_Length)\n","padded_sequence = pad_sequence(X, batch_first=True) # X is now padded sequence\n","print(padded_sequence)\n","print(padded_sequence.shape)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[15, 10,  4,  4, 17, 11, 16, 17,  6,  4,  3,  0,  0],\n","        [ 1,  2,  3,  5,  2, 18, 15,  7,  0,  0,  0,  0,  0],\n","        [14,  9,  4, 14, 13,  4,  9,  7,  2, 17,  5,  0,  0],\n","        [12,  9,  7, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [ 8, 15, 17,  6,  7, 11, 14,  2,  6, 14, 13,  2,  7]])\n","torch.Size([5, 13])\n"]}]},{"cell_type":"markdown","metadata":{"id":"o2-fxSO81tXv"},"source":["# `pack_sequence` 함수를 이용하여 PackedSequence 만들기\n","\n","input을 길이에 따른 내림차순으로 정렬"]},{"cell_type":"code","metadata":{"id":"rWVDzPn51tXv","outputId":"b5165915-824c-4a60-cf71-7a03728200ac"},"source":["# Sort by descending lengths\n","sorted_idx = sorted(range(len(lengths)), key=lengths.__getitem__, reverse=True)\n","sorted_X = [X[idx] for idx in sorted_idx]\n","\n","# Check converted result\n","for sequence in sorted_X:\n","    print(sequence)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 8, 15, 17,  6,  7, 11, 14,  2,  6, 14, 13,  2,  7])\n","tensor([15, 10,  4,  4, 17, 11, 16, 17,  6,  4,  3])\n","tensor([14,  9,  4, 14, 13,  4,  9,  7,  2, 17,  5])\n","tensor([ 1,  2,  3,  5,  2, 18, 15,  7])\n","tensor([12,  9,  7, 15])\n"]}]},{"cell_type":"markdown","metadata":{"id":"1yyV1r731tXw"},"source":["'pack_sequence'를 이용하여 PackedSequence 만들기"]},{"cell_type":"code","metadata":{"id":"vzZPsI7n1tXw","outputId":"1dc014a1-86f7-4a43-9ac3-6fef23b1289e"},"source":["packed_sequence = pack_sequence(sorted_X)\n","print(packed_sequence)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["PackedSequence(data=tensor([ 8, 15, 14,  1, 12, 15, 10,  9,  2,  9, 17,  4,  4,  3,  7,  6,  4, 14,\n","         5, 15,  7, 17, 13,  2, 11, 11,  4, 18, 14, 16,  9, 15,  2, 17,  7,  7,\n","         6,  6,  2, 14,  4, 17, 13,  3,  5,  2,  7]), batch_sizes=tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1]))\n"]}]},{"cell_type":"markdown","metadata":{"id":"j999u9Iv1tXw"},"source":["# Embedding 적용\n","one-hot character embedding"]},{"cell_type":"code","metadata":{"id":"XtWxx3Zu1tXw","outputId":"b457199f-047a-403a-92a7-5774d6dc6e03"},"source":["# one-hot embedding using PaddedSequence\n","eye = torch.eye(len(char_set)) # Identity matrix of shape (len(char_set), len(char_set))\n","embedded_tensor = eye[padded_sequence]\n","print(embedded_tensor.shape) # shape: (Batch_size, max_sequence_length, number_of_input_tokens)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([5, 13, 19])\n"]}]},{"cell_type":"code","metadata":{"id":"LRPyjGRG1tXw","outputId":"12c694fa-34a0-4cb6-bc09-54a31fc812f5"},"source":["# one-hot embedding using PackedSequence\n","embedded_packed_seq = pack_sequence([eye[X[idx]] for idx in sorted_idx])\n","print(embedded_packed_seq.data.shape)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([47, 19])\n"]}]},{"cell_type":"markdown","metadata":{"id":"bBmbxONd1tXx"},"source":["# RNN 모델"]},{"cell_type":"code","metadata":{"id":"yE6H3m5L1tXx"},"source":["rnn = torch.nn.RNN(input_size=len(char_set), hidden_size=30, batch_first=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PfIYeejj1tXx"},"source":["PaddedSequence -> RNN"]},{"cell_type":"code","metadata":{"id":"uTW76QIA1tXx","outputId":"21e41af5-496d-4753-f7da-bcbb5bd0ed8c"},"source":["rnn_output, hidden = rnn(embedded_tensor)\n","print(rnn_output.shape) # shape: (batch_size, max_seq_length, hidden_size)\n","print(hidden.shape)     # shape: (num_layers * num_directions, batch_size, hidden_size)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([5, 13, 30])\n","torch.Size([1, 5, 30])\n"]}]},{"cell_type":"markdown","metadata":{"id":"qWXY8Mui1tXx"},"source":["PackedSequence -> RNN"]},{"cell_type":"code","metadata":{"id":"1xkmrgJe1tXx","outputId":"c7252ba9-f5a0-4e8b-deb3-a038cebd2441"},"source":["rnn_output, hidden = rnn(embedded_packed_seq)\n","print(rnn_output.data.shape)\n","print(hidden.data.shape)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([47, 30])\n","torch.Size([1, 5, 30])\n"]}]},{"cell_type":"markdown","metadata":{"id":"SgPeyxqs1tXy"},"source":["# pad_packed_sequence\n"]},{"cell_type":"code","metadata":{"id":"-o4u31zB1tXy","outputId":"1f0f509a-638a-4885-c95a-384850a821e7"},"source":["unpacked_sequence, seq_lengths = pad_packed_sequence(embedded_packed_seq, batch_first=True)\n","print(unpacked_sequence.shape)\n","print(seq_lengths)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([5, 13, 19])\n","tensor([13, 11, 11,  8,  4])\n"]}]},{"cell_type":"markdown","metadata":{"id":"DW7z0CSx1tXy"},"source":["# pack_padded_sequence\n","Padding이 된 Tensor인 'PaddedSequence'를 'PackedSequence'로 바꾸어주는 함수"]},{"cell_type":"code","metadata":{"id":"UHK9znOg1tXy","outputId":"0fd656a4-be79-429f-b359-42c3df741d20"},"source":["embedded_padded_sequence = eye[pad_sequence(sorted_X, batch_first=True)]\n","print(embedded_padded_sequence.shape)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([5, 13, 19])\n"]}]},{"cell_type":"markdown","metadata":{"id":"eWP_IUpb1tXz"},"source":["padding이 된 Tensor를 PackedSequence로 변환"]},{"cell_type":"code","metadata":{"id":"Sup6tql91tXz","outputId":"655f78b5-578d-44f4-b540-27edaf7979d0"},"source":["sorted_lengths = sorted(lengths, reverse=True)\n","new_packed_sequence = pack_padded_sequence(embedded_padded_sequence, sorted_lengths, batch_first=True)\n","print(new_packed_sequence.data.shape)\n","print(new_packed_sequence.batch_sizes)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([47, 19])\n","tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1])\n"]}]}]}