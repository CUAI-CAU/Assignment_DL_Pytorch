{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11-6_신재현.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j17Z1yn2_zOf"
      },
      "source": [
        "## PackedSequence 와 PaddedSequence"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALYn0ULkAPVO"
      },
      "source": [
        "이 튜토리얼에서는 RNN / LSTM 계열의 모델에서 sequence batch를 잘 활용할 수 있는 PackedSequence 와 PaddedSequence를 만드는 법을 배워보겠습니다.\n",
        "\n",
        "PyTorch 라이브러리 안에는 다음 4가지 함수들이 주어집니다.\n",
        "\n",
        "pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "하지만 함수 이름만 봐서는 상당히 헷갈릴 수 있기 때문에 다음 그림을 참고하시면 이해하기 편하실 것 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcugEp-mAP3b"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qw01f8vAWKy",
        "outputId": "a2661810-731c-4e9c-be70-8bf4340e4ff3"
      },
      "source": [
        "# Random word from random word generator\n",
        "data = ['hello world',\n",
        "        'midnight',\n",
        "        'calculation',\n",
        "        'path',\n",
        "        'short circuit']\n",
        "\n",
        "# Make dictionary\n",
        "char_set = ['<pad>'] + list(set(char for seq in data for char in seq)) # Get all characters and include pad token\n",
        "char2idx = {char: idx for idx, char in enumerate(char_set)} # Constuct character to index dictionary\n",
        "print('char_set:', char_set)\n",
        "print('char_set length:', len(char_set))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "char_set: ['<pad>', 'l', 's', 'w', 'u', 'g', 'o', 'c', 'r', 'i', 'm', 't', 'e', 'h', 'p', 'a', ' ', 'n', 'd']\n",
            "char_set length: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtR9OcIzAZtf",
        "outputId": "2dfb3343-7fc8-46a3-b699-ca95a3379ca5"
      },
      "source": [
        "# Convert character to index and make list of tensors\n",
        "X = [torch.LongTensor([char2idx[char] for char in seq]) for seq in data]\n",
        "\n",
        "# Check converted result\n",
        "for sequence in X:\n",
        "    print(sequence)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([13, 12,  1,  1,  6, 16,  3,  6,  8,  1, 18])\n",
            "tensor([10,  9, 18, 17,  9,  5, 13, 11])\n",
            "tensor([ 7, 15,  1,  7,  4,  1, 15, 11,  9,  6, 17])\n",
            "tensor([14, 15, 11, 13])\n",
            "tensor([ 2, 13,  6,  8, 11, 16,  7,  9,  8,  7,  4,  9, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSUQY2RtAaYw",
        "outputId": "a456fcbd-2c4e-4b0a-862d-27e4521d5701"
      },
      "source": [
        "# Make length tensor (will be used later in 'pack_padded_sequence' function)\n",
        "lengths = [len(seq) for seq in X]\n",
        "print('lengths:', lengths)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lengths: [11, 8, 11, 4, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tISKoO9_Ad1c",
        "outputId": "94078601-1bf6-49cb-a7fb-7b97027f97bd"
      },
      "source": [
        "# Make a Tensor of shape (Batch x Maximum_Sequence_Length)\n",
        "padded_sequence = pad_sequence(X, batch_first=True) # X is now padded sequence\n",
        "print(padded_sequence)\n",
        "print(padded_sequence.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13, 12,  1,  1,  6, 16,  3,  6,  8,  1, 18,  0,  0],\n",
            "        [10,  9, 18, 17,  9,  5, 13, 11,  0,  0,  0,  0,  0],\n",
            "        [ 7, 15,  1,  7,  4,  1, 15, 11,  9,  6, 17,  0,  0],\n",
            "        [14, 15, 11, 13,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 2, 13,  6,  8, 11, 16,  7,  9,  8,  7,  4,  9, 11]])\n",
            "torch.Size([5, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOdWVtaLAg6Y",
        "outputId": "47a33d71-8860-4793-fe8d-c414887e59d3"
      },
      "source": [
        "# Sort by descending lengths\n",
        "sorted_idx = sorted(range(len(lengths)), key=lengths.__getitem__, reverse=True)\n",
        "sorted_X = [X[idx] for idx in sorted_idx]\n",
        "\n",
        "# Check converted result\n",
        "for sequence in sorted_X:\n",
        "    print(sequence)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2, 13,  6,  8, 11, 16,  7,  9,  8,  7,  4,  9, 11])\n",
            "tensor([13, 12,  1,  1,  6, 16,  3,  6,  8,  1, 18])\n",
            "tensor([ 7, 15,  1,  7,  4,  1, 15, 11,  9,  6, 17])\n",
            "tensor([10,  9, 18, 17,  9,  5, 13, 11])\n",
            "tensor([14, 15, 11, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGKOpiXRAinG",
        "outputId": "af01183b-ef39-4ad0-b7f0-2c26626bf286"
      },
      "source": [
        "packed_sequence = pack_sequence(sorted_X)\n",
        "print(packed_sequence)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PackedSequence(data=tensor([ 2, 13,  7, 10, 14, 13, 12, 15,  9, 15,  6,  1,  1, 18, 11,  8,  1,  7,\n",
            "        17, 13, 11,  6,  4,  9, 16, 16,  1,  5,  7,  3, 15, 13,  9,  6, 11, 11,\n",
            "         8,  8,  9,  7,  1,  6,  4, 18, 17,  9, 11]), batch_sizes=tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1]), sorted_indices=None, unsorted_indices=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrgX8JU3AnDK",
        "outputId": "7ca85b51-8077-4440-d2d1-0b66c79b4fc4"
      },
      "source": [
        "# one-hot embedding using PaddedSequence\n",
        "eye = torch.eye(len(char_set)) # Identity matrix of shape (len(char_set), len(char_set))\n",
        "embedded_tensor = eye[padded_sequence]\n",
        "print(embedded_tensor.shape) # shape: (Batch_size, max_sequence_length, number_of_input_tokens)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 13, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsjwYZy_Apt6",
        "outputId": "093a664f-0af8-45bf-bf8d-7da49d6c84ce"
      },
      "source": [
        "# one-hot embedding using PackedSequence\n",
        "embedded_packed_seq = pack_sequence([eye[X[idx]] for idx in sorted_idx])\n",
        "print(embedded_packed_seq.data.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([47, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0asvPdEAqO-"
      },
      "source": [
        "# declare RNN\n",
        "rnn = torch.nn.RNN(input_size=len(char_set), hidden_size=30, batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioajyvptAsSD"
      },
      "source": [
        "rnn_output, hidden = rnn(embedded_tensor)\n",
        "print(rnn_output.shape) # shape: (batch_size, max_seq_length, hidden_size)\n",
        "print(hidden.shape)     # shape: (num_layers * num_directions, batch_size, hidden_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoASVsnpAuOw"
      },
      "source": [
        "rnn_output, hidden = rnn(embedded_packed_seq)\n",
        "print(rnn_output.data.shape)\n",
        "print(hidden.data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUBvoxogAwQ5"
      },
      "source": [
        "unpacked_sequence, seq_lengths = pad_packed_sequence(embedded_packed_seq, batch_first=True)\n",
        "print(unpacked_sequence.shape)\n",
        "print(seq_lengths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYNnKxdlAze5"
      },
      "source": [
        "embedded_padded_sequence = eye[pad_sequence(sorted_X, batch_first=True)]\n",
        "print(embedded_padded_sequence.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGI_tdE_A2Be"
      },
      "source": [
        "sorted_lengths = sorted(lengths, reverse=True)\n",
        "new_packed_sequence = pack_padded_sequence(embedded_padded_sequence, sorted_lengths, batch_first=True)\n",
        "print(new_packed_sequence.data.shape)\n",
        "print(new_packed_sequence.batch_sizes)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}